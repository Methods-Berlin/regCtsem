% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/approx_optimization.R
\name{approx_iterateOverLambdas}
\alias{approx_iterateOverLambdas}
\title{approx_iterateOverLambdas}
\usage{
approx_iterateOverLambdas(
  cpptsemObject = NULL,
  dataset = NULL,
  sampleSize = NULL,
  regIndicators,
  lambdas,
  penalty = "lasso",
  adaptiveLassoWeights = NULL,
  targetVector,
  returnFitIndices = TRUE,
  BICWithNAndT = TRUE,
  Tpoints = NULL,
  optimizer = "BFGS",
  objective = "ML",
  epsilon = 0.001,
  zeroThresh = 0.001,
  maxIt = 200,
  scaleLambdaWithN,
  verbose = 0
)
}
\arguments{
\item{cpptsemObject}{Fitted object of type cpptsem}

\item{dataset}{wide data set}

\item{sampleSize}{sample size}

\item{regIndicators}{matrix with ones and zeros specifying which parameters in regOn should be regularized. Must be of same size as the regularized matrix. 1 = regularized, 0 = not regularized. Alternatively, labels for the regularized parameters can be used (e.g. drift_eta1_eta2)}

\item{lambdas}{vector of penalty values (tuning parameter). E.g., seq(0,1,.01)}

\item{penalty}{type. Currently supported are lasso and ridge for optimization = approx and lasso for optimization = exact}

\item{adaptiveLassoWeights}{weights for the adaptive lasso.}

\item{targetVector}{named vector with values towards which the parameters are regularized (Standard is regularization towards zero)}

\item{returnFitIndices}{Boolean: should fit indices be returned?}

\item{BICWithNAndT}{Boolean: TRUE = Use N and T in the formula for the BIC (-2log L + log(N+T)*k, where k is the number of parameters in the model). FALSE = Use both N in the formula for the BIC (-2log L + log(N))}

\item{Tpoints}{Number of time points (used for BICWithNAndT)}

\item{optimizer}{Any of the optimizers from optimx}

\item{objective}{which objective should be used? Possible are "ML" (Maximum Likelihood) or "Kalman" (Kalman Filter)}

\item{epsilon}{epsilon is used to transform the non-differentiable lasso penalty to a differentiable one if optimization = approx}

\item{zeroThresh}{threshold below which parameters will be evaluated as == 0 in lasso regularization if optimization = approx}

\item{maxIt}{maximal number of iterations given to the optimizer}

\item{scaleLambdaWithN}{Boolean: Should the penalty value be scaled with the sample size? True is recommended, as the likelihood is also sample size dependent}

\item{verbose}{0 (default), 1 for convergence plot, 2 for parameter convergence plot and line search progress}
}
\description{
loops over lambdas if optimization = "approx"
}
\details{
NOTE: Function located in file approx_optimization.R
}
\author{
Jannik Orzek
}
