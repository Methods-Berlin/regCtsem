% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/approx_optimization.R
\name{approx_iterateOverLambdas}
\alias{approx_iterateOverLambdas}
\title{approx_iterateOverLambdas}
\usage{
approx_iterateOverLambdas(
  ctsemObject = NULL,
  mxObject = NULL,
  sampleSize = NULL,
  regOn = "DRIFT",
  regIndicators,
  lambdas,
  penalty = "lasso",
  adaptiveLassoWeights = NULL,
  returnFitIndices = TRUE,
  cvSample = NULL,
  autoCV = FALSE,
  k = 5,
  objective = "ML",
  epsilon = 0.001,
  zeroThresh = 0.001,
  extraTries = 1,
  scaleLambdaWithN,
  cores = 1,
  verbose = 0,
  silent = FALSE,
  progressBar = TRUE,
  parallelProgressBar = NULL
)
}
\arguments{
\item{ctsemObject}{Fitted object of class ctsemFit}

\item{mxObject}{Fitted object of class MxObject extracted from ctsemObject. Provide either ctsemObject or mxObject}

\item{sampleSize}{sample size}

\item{regOn}{string specifying which matrix should be regularized. Currently only supports DRIFT}

\item{regIndicators}{matrix with ones and zeros specifying which parameters in regOn should be regularized. Must be of same size as the regularized matrix. 1 = regularized, 0 = not regularized. Alternatively, labels for the regularized parameters can be used (e.g. drift_eta1_eta2)}

\item{lambdas}{vector of penalty values (tuning parameter). E.g., seq(0,1,.01)}

\item{penalty}{type. Currently supported are lasso and ridge for optimization = approx and lasso for optimization = exact}

\item{adaptiveLassoWeights}{weights for the adaptive lasso.}

\item{returnFitIndices}{Boolean: should fit indices be returned?}

\item{cvSample}{cross-validation sample. Has to be of type mxData}

\item{autoCV}{Boolean: Should automatic cross-validation be used?}

\item{k}{number of cross-validation folds if autoCV = TRUE (k-fold cross-validation)}

\item{objective}{which objective should be used? Possible are "ML" (Maximum Likelihood) or "Kalman" (Kalman Filter)}

\item{epsilon}{epsilon is used to transform the non-differentiable lasso penalty to a differentiable one if optimization = approx}

\item{zeroThresh}{threshold below which parameters will be evaluated as == 0 in lasso regularization if optimization = approx}

\item{extraTries}{number of extra tries in mxTryHard}

\item{scaleLambdaWithN}{Boolean: Should the penalty value be scaled with the sample size? True is recommended, as the likelihood is also sample size dependent}

\item{cores}{how many computer cores should be used?}

\item{verbose}{0 (default), 1 for convergence plot, 2 for parameter convergence plot and line search progress}

\item{silent}{silent execution}

\item{progressBar}{Boolean: Should a progress bar be displayed}

\item{parallelProgressBar}{list: used internally to display progress when executing in parallel}
}
\description{
loops over lambdas if optimization = "approx"
}
\details{
NOTE: Function located in file approx_optimization.R
}
\author{
Jannik Orzek
}
