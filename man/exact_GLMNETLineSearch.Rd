% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/exact_GLMNETLineSearch.R
\name{exact_GLMNETLineSearch}
\alias{exact_GLMNETLineSearch}
\title{exact_GLMNETLineSearch}
\usage{
exact_GLMNETLineSearch(
  gradientModel,
  objective,
  gradientModelcpp,
  adaptiveLassoWeights,
  thetaNames,
  regIndicators,
  lambda,
  theta_kp1,
  m2LL_kp1,
  g_kp1,
  H_k,
  d,
  differenceApprox,
  eps_numericDerivative,
  stepSize,
  sig,
  gam = 0,
  maxIter_line
)
}
\arguments{
\item{gradientModel}{Object of Type MxModel which specifies how the gradients of the likelihood-function are computed (the jacobian)}

\item{objective}{which objective should be used? Possible are "ML" (Maximum Likelihood) or "Kalman" (Kalman Filter)}

\item{gradientModelcpp}{cpptsem object which specifies how the gradients of the likelihood-function are computed (the jacobian)}

\item{adaptiveLassoWeights}{weights for the adaptive lasso.}

\item{thetaNames}{names of the parameter estimates}

\item{regIndicators}{vector with names of parameters to regularize}

\item{lambda}{penalty value}

\item{theta_kp1}{parameter values of iteration k plus 1}

\item{m2LL_kp1}{-2 log likelihood of iteration k plus 1}

\item{g_kp1}{gradients of iteration k plus 1}

\item{d}{vector with updates to parameter estimates}

\item{differenceApprox}{which approximation for the gradients should be used? Recommended is central}

\item{eps_numericDerivative}{controls the precision of the central gradient approximation. The default (1.1 * 10^(-16))^(1/3) is derived in Nocedal, J., & Wright, S. J. (2006). Numerical optimization (2nd ed), p. 197}

\item{stepSize}{Initial stepsize of the outer iteration (theta_{k+1} = theta_k + Stepsize \* Stepdirection)}

\item{sig}{GLMNET & GIST: GLMNET: only relevant when lineSearch = 'GLMNET' | GIST: sigma value in Gong et al. (2013). Sigma controls the inner stopping criterion and must be in (0,1). Generally, a larger sigma enforce a steeper decrease in the regularized likelihood while a smaller sigma will result in faster acceptance of the inner iteration.}

\item{gam}{GLMNET when lineSearch = 'GLMNET'. Controls the gamma parameter in Yuan, G.-X., Ho, C.-H., & Lin, C.-J. (2012). An improved GLMNET for l1-regularized logistic regression. The Journal of Machine Learning Research, 13, 1999–2030. https://doi.org/10.1145/2020408.2020421. Defaults to 0.}

\item{maxIter_line}{maximal number of iterations for line search}
}
\description{
performs the line search procedure described by Yuan, G.-X., Ho, C.-H., & Lin, C.-J. (2012). An improved GLMNET for l1-regularized logistic regression. The Journal of Machine Learning Research, 13, 1999–2030. https://doi.org/10.1145/2020408.2020421 Equation 20.
}
